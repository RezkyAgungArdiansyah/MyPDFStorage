{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20947ff1",
   "metadata": {},
   "source": [
    "# Name Entity Recognition with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca59b3",
   "metadata": {},
   "source": [
    "**Named Enitity Recognition** is a common problem in NLP dealing with identifying and classifying named entities.\n",
    "\n",
    "A named entity is a real life object which has an indentification and can be defined by a name. A place, person, countries or organizations can be a named entity. For example, Microsoft is an organization and Asia is a geographic entity.\n",
    "\n",
    "A raw or unstructed data is processed and by using the help of named enitity recognition, one can label and classify the data as different entities. A NER system is developed with the help of linguistic approches and statiscal methods.\n",
    "\n",
    "A NER model begins with identifying an entity and categorizes into the most suitable class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f88d04",
   "metadata": {},
   "source": [
    "Practical Applications of NER:\n",
    "\n",
    "-- Scanning through large documents and finding people, organizations and locations available.\n",
    "\n",
    "-- We could optimize the search by providing the key entities found.\n",
    "\n",
    "-- Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666829f",
   "metadata": {},
   "source": [
    "**Named Entity Recognition with spaCy**:\n",
    "\n",
    "SpaCy is an open source Natural processing library with fast statistical entity recognition system. The methods that are available in SpaCy for NER assigns a label to the text data and classifies the same as defined above.\n",
    "\n",
    "Spacy also provides us an option to add arbitrary classes to entity recognition systems and update the model to include new examples. We can train our own data for business-specific needs and prepare the model as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4707842",
   "metadata": {},
   "source": [
    "Spacy Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91d939",
   "metadata": {},
   "source": [
    "pip install spacy\n",
    "\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a74ae852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:31:12.415252Z",
     "start_time": "2024-03-04T13:31:11.195164Z"
    }
   },
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72755847",
   "metadata": {},
   "source": [
    "en_core_web_sm is a small English pipeline trained on written web text (blogs, news, comments), that includes vocabulary, syntax and entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2189b",
   "metadata": {},
   "source": [
    "**Naming convention of the package**\n",
    "Type: Capabilities (e.g. core for general-purpose pipeline with tagging, parsing, lemmatization and named entity recognition, or dep for only tagging, parsing and lemmatization). Genre: Type of text the pipeline is trained on, e.g. web or news. Size: Package size indicator, sm, md, lg or trf.\n",
    "\n",
    "Spacy provides predefined models for many languages and they can be found in the URL: https://spacy.io/models. Predict part-of-speech tags, dependency labels, named entities and more.\n",
    "\n",
    "When a text is passed into nlp, it goes through each of the pipeline as shown in the image:\n",
    "![Example Image](Capture.PNG)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6b7cbf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:31:30.980659Z",
     "start_time": "2024-03-04T13:31:30.964951Z"
    }
   },
   "source": [
    "doc = nlp(\"I live in Taipei\")\n",
    "for word in doc.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6db149",
   "metadata": {},
   "source": [
    "Taipei is GPE - Geo-Political Entity\n",
    "\n",
    "Just in case, if you are wondering what the meaning could be of the label returned. We could use the below:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abdf4659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:31:47.427687Z",
     "start_time": "2024-03-04T13:31:47.422748Z"
    }
   },
   "source": [
    "spacy.explain('GPE'), spacy.explain('ORG'),spacy.explain('MONEY') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915065b2",
   "metadata": {},
   "source": [
    "The labels and output are self-explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acad145",
   "metadata": {},
   "source": [
    "**spaCy supports the following entity types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbab938",
   "metadata": {},
   "source": [
    "PERSON, NORP (nationalities, religious and political groups), FAC (buildings, airports etc.), ORG (organizations), GPE (countries, cities etc.), LOC (mountain ranges, water bodies etc.), PRODUCT (products), EVENT (event names), WORK_OF_ART (books, song titles), LAW (legal document titles), LANGUAGE (named languages), DATE, TIME, PERCENT, MONEY, QUANTITY, ORDINAL and CARDINAL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843adc42",
   "metadata": {},
   "source": [
    "**Visualize dependencies**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e325b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:32:08.262511Z",
     "start_time": "2024-03-04T13:32:08.255776Z"
    }
   },
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"I live in Taipei\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f008b22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:32:24.476672Z",
     "start_time": "2024-03-04T13:32:24.469870Z"
    }
   },
   "source": [
    "doc = nlp(\"Bill Gates and Paul Allen founded Microsoft\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fdffeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:32:41.797482Z",
     "start_time": "2024-03-04T13:32:41.785940Z"
    }
   },
   "source": [
    "doc = nlp(\"Reaffirming his support to the memecoin, billionaire Elon Musk said that he will keep supporting and buying dogecoin. His support for the cryptocurrency comes amid the recent crypto market meltdown and days after him being hit with $258 billion ‘dogecoin pyramid scheme' lawsuit.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_, ent.start, ent.ent_id_, ent.label, ent.vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55410bd9",
   "metadata": {},
   "source": [
    "1. Entity text by using ent.text,\n",
    "2. Starting and ending character of an entity by using ent.start_char and ent.end_char,\n",
    "3. Entity’s index by using ent.start,\n",
    "4. Entity type’s id by using ent.entid,\n",
    "5. Generate vector norm of an entity by using ent.vector_norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e4a3c",
   "metadata": {},
   "source": [
    "# Adding new Named Entities in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b5de1",
   "metadata": {},
   "source": [
    "In cases like if we need a new entity in the model, we could follow the steps below to create an entity and include it in the model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b900c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:43:16.076631Z",
     "start_time": "2024-03-04T13:43:16.068891Z"
    }
   },
   "source": [
    "doc = nlp('Dogecoin is a parody cryptocurrency created by software engineer Billy Markus and Jackson Palmer in 2013.')\n",
    "for word in doc.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20382350",
   "metadata": {},
   "source": [
    "Dogecoin is a cryptocurrency and it is not recognized by spaCy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f6aaf80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:43:37.118263Z",
     "start_time": "2024-03-04T13:43:37.116328Z"
    }
   },
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "new_ent = Span(doc, 0, 1, label = \"MONEY\")\n",
    "doc.set_ents([new_ent], default = 'unmodified')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9254138e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:43:50.009216Z",
     "start_time": "2024-03-04T13:43:50.006636Z"
    }
   },
   "source": [
    "for word in doc.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76dfc5d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:44:09.210310Z",
     "start_time": "2024-03-04T13:44:09.207987Z"
    }
   },
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2f6df",
   "metadata": {},
   "source": [
    "Dogecoin is now considered as MONEY. Just in case if we have numerous cryptocurrencies in our data to be entitled as MONEY, we could find the SPAN and update the label as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1787f2",
   "metadata": {},
   "source": [
    "# Adding Named Entities to Matching Spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719ce7c",
   "metadata": {},
   "source": [
    "PhraseMatcher is used to identify a series of span in a doc. When the matched spans are identified, we could tag all of them with the corresponding entity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e0a80f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:44:22.672382Z",
     "start_time": "2024-03-04T13:44:22.663993Z"
    }
   },
   "source": [
    "doc = nlp('We are launching a new robot at the end of July. According to sales, we may increase the production of robots.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf28d46",
   "metadata": {},
   "source": [
    "This only gives us the end of July as the DATE entity, but we also want the spaCy to identify robot as a Product. Hence, we are using Phrase matcher and adding the label as shown below:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bc284c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:44:42.053023Z",
     "start_time": "2024-03-04T13:44:42.043727Z"
    }
   },
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "phrase_list = ['robot', 'robots']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "matches = matcher(doc)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51315dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:44:53.219492Z",
     "start_time": "2024-03-04T13:44:53.217237Z"
    }
   },
   "source": [
    "new_ents = [Span(doc, match[1], match[2], label = 'PRODUCT') for match in matches]\n",
    "doc.set_ents(new_ents, default = 'unmodified')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb9b31a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:45:04.839488Z",
     "start_time": "2024-03-04T13:45:04.837089Z"
    }
   },
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b37b1",
   "metadata": {},
   "source": [
    "We have added robot as a product to the labels now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef70bb",
   "metadata": {},
   "source": [
    "# How to train a custom NER Model is spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1c581",
   "metadata": {},
   "source": [
    "To train the model, we will need relevant data with proper annotations. I have used the medical entities dataset here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ae3d1",
   "metadata": {},
   "source": [
    "Install the spacy-tranformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e04f8",
   "metadata": {},
   "source": [
    "pip install spacy[transformers]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "faa09d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:52:04.139586Z",
     "start_time": "2024-03-04T13:52:04.136368Z"
    }
   },
   "source": [
    "import json\n",
    " \n",
    "with open('Corona2.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(data['examples'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf74f9",
   "metadata": {},
   "source": [
    "We are extracting the text and corresponding annotations and creating a structed data below"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39a12b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:52:22.184687Z",
     "start_time": "2024-03-04T13:52:22.181921Z"
    }
   },
   "source": [
    "training_data = {'classes' : ['MEDICINE', \"MEDICALCONDITION\", \"PATHOGEN\"], 'annotations' : []}\n",
    "for example in data['examples']:\n",
    "  temp_dict = {}\n",
    "  temp_dict['text'] = example['content']\n",
    "  temp_dict['entities'] = []\n",
    "  for annotation in example['annotations']:\n",
    "    start = annotation['start']\n",
    "    end = annotation['end']\n",
    "    label = annotation['tag_name'].upper()\n",
    "    temp_dict['entities'].append((start, end, label))\n",
    "  training_data['annotations'].append(temp_dict)\n",
    "  \n",
    "print(training_data['annotations'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61deab5d",
   "metadata": {},
   "source": [
    "For the data in text above, we have the labels with their corresponding span."
   ]
  },
  {
   "cell_type": "raw",
   "id": "169096ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:52:33.075363Z",
     "start_time": "2024-03-04T13:52:32.987392Z"
    }
   },
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "doc_bin = DocBin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc6625",
   "metadata": {},
   "source": [
    "spaCy uses **DocBin** class for annotated data, so we’ll have to create the DocBin objects for our training examples. This DocBin class efficiently serializes the information from a collection of Doc objects. It is faster and produces smaller data sizes than pickle, and allows the user to deserialize without executing arbitrary Python code.\n",
    "\n",
    "The indices of some entities overlap. spaCy provides a utility method filter_spans to deal with this."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1972f93b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:52:47.557240Z",
     "start_time": "2024-03-04T13:52:47.512811Z"
    }
   },
   "source": [
    "from spacy.util import filter_spans\n",
    "\n",
    "for training_example  in tqdm(training_data['annotations']): \n",
    "    text = training_example['text']\n",
    "    labels = training_example['entities']\n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for start, end, label in labels:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents \n",
    "    doc_bin.add(doc)\n",
    "\n",
    "doc_bin.to_disk(\"./training_data.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e3869",
   "metadata": {},
   "source": [
    "The DocBin saves the Training_Data in Spacy format which we need to train a model. Then, We can manually create a config file as per the use case or quickly create a base config on spaCy’s training quickstart page here.\n",
    "![Example Image](docbin.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24a5a9",
   "metadata": {},
   "source": [
    "We’ll be working with a base config file using the quickstart page. This is an incomplete file with only our custom options, so we’ll have to fill in the rest with the default values. The command below is ran in CMD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81823ced",
   "metadata": {},
   "source": [
    "python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e73bb9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:04:57.363883Z",
     "start_time": "2024-03-04T14:04:57.361997Z"
    }
   },
   "source": [
    "#access this https://spacy.io/usage/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22805391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "798b3cc6",
   "metadata": {},
   "source": [
    "Please make sure that the training data in spacy format is available in the same path before running the line above. This will create a config file in the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7de235",
   "metadata": {},
   "source": [
    "Now, as we have all that we need to train our model. Let's train the model with the line below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0185af8",
   "metadata": {},
   "source": [
    "python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307eaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfe4e7c1",
   "metadata": {},
   "source": [
    "Let’s load the best-performing model and test it on a piece of text. I had to use Anaconda Prompt to work with the command lines and so the output below was generated in Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004e3d8",
   "metadata": {},
   "source": [
    "nlp_ner = spacy.load(\"model-best\")\n",
    "\n",
    "doc = nlp_ner(training_data['annotations'][0].get('text'))\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", options= options, jupyter=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20a3bf57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:18:58.369070Z",
     "start_time": "2024-03-04T14:18:58.135149Z"
    }
   },
   "source": [
    "nlp_ner = spacy.load(\"model-best\")\n",
    "\n",
    "doc = nlp_ner(training_data['annotations'][0].get('text'))\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a402ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:21:36.577186Z",
     "start_time": "2024-03-04T14:21:36.349449Z"
    }
   },
   "source": [
    "nlp_ner = spacy.load(\"model-best\")\n",
    "\n",
    "doc = nlp_ner(training_data['annotations'][2].get('text'))\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9ad13",
   "metadata": {},
   "source": [
    "Even with the very limited amount of data the model achieves decent performance. We could follow the same steps above to train a model with different data but it should have annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac48f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghaluh",
   "language": "python",
   "name": "ghaluh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
