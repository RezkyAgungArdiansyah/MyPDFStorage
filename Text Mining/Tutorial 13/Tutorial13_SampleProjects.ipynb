{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5e619b",
   "metadata": {},
   "source": [
    "# Project #1a: Text Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0530e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    category\n",
      "0  The football match was exciting and full of ac...      Sports\n",
      "1              The government passed a new law today    Politics\n",
      "2  New advancements in artificial intelligence ar...  Technology\n",
      "3           The health benefits of yoga are numerous      Health\n",
      "4    The basketball team won their championship game      Sports\n",
      "Training data:\n",
      "5      A major political scandal has rocked the nation\n",
      "0    The football match was exciting and full of ac...\n",
      "7    A recent study shows the positive effects of m...\n",
      "2    New advancements in artificial intelligence ar...\n",
      "9      The election results will be announced tomorrow\n",
      "4      The basketball team won their championship game\n",
      "3             The health benefits of yoga are numerous\n",
      "6    Tech companies are investing in quantum computing\n",
      "Name: text, dtype: object\n",
      "Testing data:\n",
      "8    The tennis player won her third grand slam title\n",
      "1               The government passed a new law today\n",
      "Name: text, dtype: object\n",
      "BoW Feature Names:\n",
      "['action' 'advancements' 'and' 'announced' 'are' 'artificial' 'basketball'\n",
      " 'be' 'benefits' 'championship' 'companies' 'computing' 'effects'\n",
      " 'election' 'exciting' 'football' 'full' 'game' 'has' 'health' 'in'\n",
      " 'intelligence' 'investing' 'major' 'match' 'meditation' 'mental' 'nation'\n",
      " 'new' 'numerous' 'of' 'on' 'political' 'positive' 'quantum' 'recent'\n",
      " 'remarkable' 'results' 'rocked' 'scandal' 'shows' 'study' 'team' 'tech'\n",
      " 'the' 'their' 'tomorrow' 'was' 'will' 'won' 'yoga']\n",
      "Training data (BoW):\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      "  0 0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1\n",
      "  0 0 0 0 1 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 1 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 1 1 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "TF-IDF Feature Names:\n",
      "['action' 'advancements' 'and' 'announced' 'are' 'artificial' 'basketball'\n",
      " 'be' 'benefits' 'championship' 'companies' 'computing' 'effects'\n",
      " 'election' 'exciting' 'football' 'full' 'game' 'has' 'health' 'in'\n",
      " 'intelligence' 'investing' 'major' 'match' 'meditation' 'mental' 'nation'\n",
      " 'new' 'numerous' 'of' 'on' 'political' 'positive' 'quantum' 'recent'\n",
      " 'remarkable' 'results' 'rocked' 'scandal' 'shows' 'study' 'team' 'tech'\n",
      " 'the' 'their' 'tomorrow' 'was' 'will' 'won' 'yoga']\n",
      "Training data (TF-IDF):\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40000925 0.         0.         0.         0.         0.40000925\n",
      "  0.         0.         0.         0.40000925 0.         0.\n",
      "  0.         0.         0.40000925 0.         0.         0.\n",
      "  0.         0.         0.40000925 0.40000925 0.         0.\n",
      "  0.         0.         0.19988893 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.35868526 0.         0.35868526 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.35868526 0.35868526 0.35868526 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35868526 0.         0.         0.         0.         0.\n",
      "  0.25939852 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17923889 0.         0.         0.35868526\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32486899 0.         0.         0.         0.         0.\n",
      "  0.         0.27226557 0.         0.         0.         0.\n",
      "  0.         0.32486899 0.32486899 0.         0.         0.\n",
      "  0.23494284 0.32486899 0.         0.32486899 0.         0.32486899\n",
      "  0.         0.         0.         0.         0.32486899 0.32486899\n",
      "  0.         0.         0.16234053 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.4007901  0.         0.         0.28984843 0.4007901\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33589338 0.4007901  0.         0.\n",
      "  0.         0.         0.         0.         0.4007901  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4007901  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.40000925 0.         0.\n",
      "  0.         0.40000925 0.         0.         0.         0.\n",
      "  0.         0.40000925 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40000925 0.         0.         0.         0.\n",
      "  0.         0.         0.19988893 0.         0.40000925 0.\n",
      "  0.40000925 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.40000925 0.         0.         0.40000925 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40000925\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40000925 0.         0.19988893 0.40000925 0.         0.\n",
      "  0.         0.40000925 0.        ]\n",
      " [0.         0.         0.         0.         0.323483   0.\n",
      "  0.         0.         0.44729856 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3748711  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.44729856\n",
      "  0.323483   0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.2235199  0.         0.         0.\n",
      "  0.         0.         0.44729856]\n",
      " [0.         0.         0.         0.         0.28984843 0.\n",
      "  0.         0.         0.         0.         0.4007901  0.4007901\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33589338 0.         0.4007901  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4007901  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4007901  0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "Accuracy (BoW): 1.0\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       1.00      1.00      1.00         1\n",
      "      Sports       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Confusion Matrix (BoW):\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "Accuracy (TF-IDF): 0.5\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.00      0.00      0.00         1\n",
      "      Sports       1.00      1.00      1.00         1\n",
      "  Technology       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.33      0.33      0.33         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n",
      "Confusion Matrix (TF-IDF):\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    'text': [\n",
    "        'The football match was exciting and full of action',\n",
    "        'The government passed a new law today',\n",
    "        'New advancements in artificial intelligence are remarkable',\n",
    "        'The health benefits of yoga are numerous',\n",
    "        'The basketball team won their championship game',\n",
    "        'A major political scandal has rocked the nation',\n",
    "        'Tech companies are investing in quantum computing',\n",
    "        'A recent study shows the positive effects of meditation on mental health',\n",
    "        'The tennis player won her third grand slam title',\n",
    "        'The election results will be announced tomorrow'\n",
    "    ],\n",
    "    'category': ['Sports', 'Politics', 'Technology', 'Health', 'Sports', 'Politics', 'Technology', 'Health', 'Sports', 'Politics']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df['text']\n",
    "y = df['category']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train)\n",
    "print(\"Testing data:\")\n",
    "print(X_test)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"BoW Feature Names:\")\n",
    "print(bow_vectorizer.get_feature_names_out())\n",
    "print(\"Training data (BoW):\")\n",
    "print(X_train_bow.toarray())\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF Feature Names:\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"Training data (TF-IDF):\")\n",
    "print(X_train_tfidf.toarray())\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr_bow = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bow = lr_bow.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy (BoW):\", accuracy_score(y_test, y_pred_bow))\n",
    "print(\"Classification Report (BoW):\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(\"Confusion Matrix (BoW):\")\n",
    "print(confusion_matrix(y_test, y_pred_bow))\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy (TF-IDF):\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(\"Confusion Matrix (TF-IDF):\")\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd55588",
   "metadata": {},
   "source": [
    "# Project #1b: Text Classification by Fine-Tuning Pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f579cb1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    category\n",
      "0  The football match was exciting and full of ac...      Sports\n",
      "1              The government passed a new law today    Politics\n",
      "2  New advancements in artificial intelligence ar...  Technology\n",
      "3           The health benefits of yoga are numerous      Health\n",
      "4    The basketball team won their championship game      Sports\n",
      "Training data:\n",
      "5      A major political scandal has rocked the nation\n",
      "0    The football match was exciting and full of ac...\n",
      "7    A recent study shows the positive effects of m...\n",
      "2    New advancements in artificial intelligence ar...\n",
      "9      The election results will be announced tomorrow\n",
      "4      The basketball team won their championship game\n",
      "3             The health benefits of yoga are numerous\n",
      "6    Tech companies are investing in quantum computing\n",
      "Name: text, dtype: object\n",
      "Testing data:\n",
      "8    The tennis player won her third grand slam title\n",
      "1               The government passed a new law today\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "Train loss 1.3960583209991455 accuracy 0.125\n",
      "Val loss 1.3168529272079468 accuracy 0.5\n",
      "Epoch 2/3\n",
      "----------\n",
      "Train loss 1.415708065032959 accuracy 0.375\n",
      "Val loss 1.277579426765442 accuracy 0.5\n",
      "Epoch 3/3\n",
      "----------\n",
      "Train loss 1.2927600145339966 accuracy 0.625\n",
      "Val loss 1.2550435066223145 accuracy 0.5\n",
      "Test Accuracy: 0.5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health       0.00      1.00      0.00         0\n",
      "    Politics       1.00      0.00      0.00         1\n",
      "      Sports       1.00      1.00      1.00         1\n",
      "  Technology       1.00      1.00      1.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.75      0.75      0.50         2\n",
      "weighted avg       1.00      0.50      0.50         2\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Sample Data \n",
    "data = {\n",
    "    'text': [\n",
    "        'The football match was exciting and full of action',\n",
    "        'The government passed a new law today',\n",
    "        'New advancements in artificial intelligence are remarkable',\n",
    "        'The health benefits of yoga are numerous',\n",
    "        'The basketball team won their championship game',\n",
    "        'A major political scandal has rocked the nation',\n",
    "        'Tech companies are investing in quantum computing',\n",
    "        'A recent study shows the positive effects of meditation on mental health',\n",
    "        'The tennis player won her third grand slam title',\n",
    "        'The election results will be announced tomorrow'\n",
    "    ],\n",
    "    'category': ['Sports', 'Politics', 'Technology', 'Health', 'Sports', 'Politics', 'Technology', 'Health', 'Sports', 'Politics']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())\n",
    "\n",
    "# Encode the labels into integers\n",
    "# LabelEncoder converts categorical labels (e.g., 'Sports', 'Politics') into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "df['category'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df['text']\n",
    "y = df['category']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "# This helps in evaluating the performance of the model on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train)\n",
    "print(\"Testing data:\")\n",
    "print(X_test)\n",
    "\n",
    "# Define a custom dataset class to handle our data\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Tokenize the text and create attention masks\n",
    "        # encode_plus helps in preparing the input in the required format for BERT\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',  # Pad to the maximum length\n",
    "            return_attention_mask=True,  # Return attention mask to differentiate between padded and actual tokens\n",
    "            return_tensors='pt',  # Return PyTorch tensors\n",
    "            truncation=True,  # Truncate sequences longer than max_len\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "# 'bert-base-uncased' refers to the pre-trained BERT model with uncased vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = 128  # Maximum length of input sequence\n",
    "\n",
    "# Create dataset objects for training and testing data\n",
    "train_dataset = NewsDataset(X_train.tolist(), y_train.tolist(), tokenizer, max_len)\n",
    "test_dataset = NewsDataset(X_test.tolist(), y_test.tolist(), tokenizer, max_len)\n",
    "\n",
    "# Create data loaders for training and testing data\n",
    "# DataLoader helps in batching, shuffling, and loading the data in parallel\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_epoch(\n",
    "    model, \n",
    "    data_loader, \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()  # Set model to training mode\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"label\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "        scheduler.step()  # Update learning rate\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "    \n",
    "    # Calculate and return average accuracy and loss for this epoch\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()  # Set model to evaluation mode\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    # Calculate and return average accuracy and loss for the evaluation\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "# Initialize the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    num_labels=len(label_encoder.classes_)  # Number of output labels\n",
    ")\n",
    "model = model.to(device)  # Move model to the appropriate device (GPU/CPU)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_loader) * 3  # Total training steps (num_epochs * num_batches_per_epoch)\n",
    "\n",
    "# Set up the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Dictionary to store training history\n",
    "history = {'train_acc': [], 'train_loss': [], 'val_acc': [], 'val_loss': []}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Train the model for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print(f'Epoch {epoch + 1}/{3}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Train the model for one epoch\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(X_train)\n",
    "    )\n",
    "    \n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(X_test)\n",
    "    )\n",
    "    \n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "    \n",
    "    # Store training and validation metrics\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_acc, _ = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(X_test)\n",
    ")\n",
    "\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "# Predictions and classification report\n",
    "model = model.eval()  # Set model to evaluation mode\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in test_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"label\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels)\n",
    "\n",
    "# Stack predictions and true labels for evaluation\n",
    "predictions = torch.stack(predictions).cpu()\n",
    "true_labels = torch.stack(true_labels).cpu()\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, labels=[0, 1, 2, 3], target_names=label_encoder.classes_, zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predictions, labels=[0, 1, 2, 3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c2c86",
   "metadata": {},
   "source": [
    "# Project #2: Text Translation by Fine-Tuning Pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b04af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss: 3.7011754512786865\n",
      "Validation loss: 2.441734552383423\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss: 2.5062824189662933\n",
      "Validation loss: 2.2136828899383545\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss: 2.128346711397171\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss: 2.162066102027893\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss: 2.1558494567871094\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss: 2.1393941044807434\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss: 1.9143696129322052\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss: 1.9473647475242615\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss: 2.5014607310295105\n",
      "Validation loss: 2.1485533714294434\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss: 2.190967470407486\n",
      "Validation loss: 2.1485533714294434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880290/639053091.py:216: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n",
      "/usr/local/lib/python3.8/dist-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello, how are you?\n",
      "Translated: Hello, how are you?\n",
      "Reference: Bonjour, comment ça va?\n",
      "\n",
      "Original: What is your name?\n",
      "Translated: Votre nom?\n",
      "Reference: Comment tu t'appelles?\n",
      "\n",
      "Original: I am fine, thank you.\n",
      "Translated: Je suis bien, merci.\n",
      "Reference: Je vais bien, merci.\n",
      "\n",
      "BLEU score: 24.80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "# Sample bilingual data for translation\n",
    "data = [\n",
    "    {'en': 'Hello, how are you?', 'fr': 'Bonjour, comment ça va?'},\n",
    "    {'en': 'What is your name?', 'fr': 'Comment tu t\\'appelles?'},\n",
    "    {'en': 'I am fine, thank you.', 'fr': 'Je vais bien, merci.'},\n",
    "    {'en': 'Good morning', 'fr': 'Bonjour'},\n",
    "    {'en': 'Good night', 'fr': 'Bonne nuit'},\n",
    "    {'en': 'See you later', 'fr': 'À plus tard'},\n",
    "    {'en': 'Thank you very much', 'fr': 'Merci beaucoup'},\n",
    "    {'en': 'You are welcome', 'fr': 'Je vous en prie'},\n",
    "    {'en': 'How much is this?', 'fr': 'Combien ça coûte?'},\n",
    "    {'en': 'Where is the bathroom?', 'fr': 'Où sont les toilettes?'}\n",
    "]\n",
    "\n",
    "# Custom dataset class for translation data\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, source_lang, target_lang, max_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tokenizer: Pre-trained tokenizer for encoding the text\n",
    "            data: List of dictionaries containing source and target language pairs\n",
    "            source_lang: Source language key in the data dictionary\n",
    "            target_lang: Target language key in the data dictionary\n",
    "            max_len: Maximum sequence length for encoding\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of data points\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve source and target text for a given index\n",
    "        source_text = self.data[idx][self.source_lang]\n",
    "        target_text = self.data[idx][self.target_lang]\n",
    "\n",
    "        # Tokenize and encode source text\n",
    "        source = self.tokenizer.encode_plus(\n",
    "            source_text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize and encode target text\n",
    "        target = self.tokenizer.encode_plus(\n",
    "            target_text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Prepare labels for loss calculation, replacing padding tokens with -100\n",
    "        labels = target['input_ids'].squeeze()\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': source['input_ids'].squeeze(),\n",
    "            'attention_mask': source['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "# Initialize the tokenizer and model from pre-trained T5 base\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Define dataset and parameters\n",
    "max_len = 50  # Maximum sequence length\n",
    "dataset = TranslationDataset(tokenizer, data, 'en', 'fr', max_len)\n",
    "\n",
    "# Split data into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2)\n",
    "\n",
    "# Define optimizer and scheduler for learning rate adjustment\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\n",
    "total_steps = len(train_loader) * 3  # Total training steps for the scheduler\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training function for one epoch\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to train\n",
    "        data_loader: DataLoader for the training data\n",
    "        optimizer: Optimizer for the model\n",
    "        device: Device (CPU or GPU) to run the training on\n",
    "        scheduler: Learning rate scheduler\n",
    "        \n",
    "    Returns:\n",
    "        Mean loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    losses = []\n",
    "\n",
    "    for data in data_loader:\n",
    "        # Move data to the specified device\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to evaluate\n",
    "        data_loader: DataLoader for the validation data\n",
    "        device: Device (CPU or GPU) to run the evaluation on\n",
    "        \n",
    "    Returns:\n",
    "        Mean loss for the validation data\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Move data to the specified device\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else CPU\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 10  # Number of training epochs\n",
    "best_loss = float('inf')  # Initialize best loss to infinity\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "    print(f'Train loss: {train_loss}')\n",
    "\n",
    "    val_loss = eval_model(model, val_loader, device)\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_translation_model.bin')\n",
    "\n",
    "# Load the best model for final evaluation\n",
    "model.load_state_dict(torch.load('best_translation_model.bin'))\n",
    "\n",
    "# Function to translate a single sentence\n",
    "def translate_sentence(model, tokenizer, sentence, device, max_len=50):\n",
    "    \"\"\"\n",
    "    Translate a given sentence using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        tokenizer: The tokenizer for encoding the input sentence\n",
    "        sentence: The input sentence to translate\n",
    "        device: Device (CPU or GPU) to run the translation on\n",
    "        max_len: Maximum length for the output sentence\n",
    "        \n",
    "    Returns:\n",
    "        The translated sentence\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(input_ids, max_length=max_len, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test the model with a few examples and calculate BLEU score\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "test_sentences = [\n",
    "    {\"en\": \"Hello, how are you?\", \"fr\": \"Bonjour, comment ça va?\"},\n",
    "    {\"en\": \"What is your name?\", \"fr\": \"Comment tu t'appelles?\"},\n",
    "    {\"en\": \"I am fine, thank you.\", \"fr\": \"Je vais bien, merci.\"}\n",
    "]\n",
    "\n",
    "references = []  # List to store reference translations\n",
    "predictions = []  # List to store model predictions\n",
    "\n",
    "for item in test_sentences:\n",
    "    original_sentence = item[\"en\"]\n",
    "    reference_translation = item[\"fr\"]\n",
    "    translated_sentence = translate_sentence(model, tokenizer, original_sentence, device)\n",
    "\n",
    "    # Print the original, translated, and reference sentences\n",
    "    print(f'Original: {original_sentence}')\n",
    "    print(f'Translated: {translated_sentence}')\n",
    "    print(f'Reference: {reference_translation}\\n')\n",
    "\n",
    "    # Add the reference and predicted translations to their respective lists\n",
    "    references.append([reference_translation])\n",
    "    predictions.append(translated_sentence)\n",
    "\n",
    "# Compute BLEU score for the translations\n",
    "bleu_score = metric.compute(predictions=predictions, references=references)\n",
    "print(f\"BLEU score: {bleu_score['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65553833",
   "metadata": {},
   "source": [
    "# Project #3a: Text Generation by Fine-Tuning Pretrained GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db5c888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.8801447394348325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.17307371823560624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.15602794147673107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.13626152135076977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.13290729763961973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.12608726535524642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.11951983861979984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.11563813810547192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.11477564754230636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.1115070909616493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.11088660927045912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.10888935838426862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.11803241570790608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.12322498325790678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.15618124959014712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.13268243255359785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.1648038150299163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.20233410454931713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.23264221350351968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.21151683976252875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.19438529653208597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.18729257370744432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.18396114256410373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.18488762917972745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.18385783653883708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.1784265995735214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.1749447834278856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.1736179469596772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.1675685825092452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.16450054872603642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.16986592291366487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.16210134824117026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.1598449115242277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.15698021721272243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.16709806521733603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.15637135115407763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.15366254711434954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.1509793759101913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.14606820330733344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.1466148147980372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.1453955311860357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.14230650273107348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.14368209668568202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.15559746821721396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.17086393785263812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.14372834651952698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.1398186289838382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.13245863822244464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.13368822172993705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.13650958310990108\n",
      "Prompt: But thou shrieking\n",
      "Generated Text: But thou shrieking\n",
      "\n",
      "Prompt: In the quiet\n",
      "Generated Text: In the quiet\n",
      "\n",
      "Prompt: On the sole\n",
      "Generated Text: On the sole\n",
      "\n",
      "Prompt: Every fowl of\n",
      "Generated Text: Every fowl of\n",
      "\n",
      "Prompt: In a mutual flame\n",
      "Generated Text: In a mutual flame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "# Load and prepare the dataset\n",
    "def load_data(file_path, tokenizer, block_size=256):\n",
    "    dataset = load_dataset('text', data_files={'train': file_path})\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, max_length=block_size, padding='max_length')\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "    return tokenized_datasets['train']\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.input_ids = tokenized_texts['input_ids']\n",
    "        self.attention_mask = tokenized_texts['attention_mask']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.attention_mask[idx])\n",
    "\n",
    "data_file = 'poems.txt'\n",
    "tokenized_datasets = load_data(data_file, tokenizer)\n",
    "dataset = TextDataset(tokenized_datasets)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-5\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, attention_masks in tqdm(dataloader):\n",
    "        inputs, attention_masks = inputs.to(device), attention_masks.to(device)\n",
    "        \n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_masks, labels=inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader)}')\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained('./gpt2_model')\n",
    "tokenizer.save_pretrained('./gpt2_tokenizer')\n",
    "\n",
    "# Generate text with the trained GPT-2 model\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0, top_k=20, top_p=0.95):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    attention_mask = torch.ones(input_ids.shape, device=device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, attention_mask=attention_mask, max_length=max_length, temperature=temperature, top_k=top_k, top_p=top_p, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.eos_token_id, do_sample=True)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example prompts for text generation\n",
    "prompts = [\n",
    "    \"But thou shrieking\",\n",
    "    \"In the quiet\",\n",
    "    \"On the sole\",\n",
    "    \"Every fowl of\",\n",
    "    \"In a mutual flame\"\n",
    "]\n",
    "\n",
    "# Generate and display text based on the example prompts\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    generated_text = generate_text(model, tokenizer, prompt, max_length=50)\n",
    "    print(f\"Generated Text: {generated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e210ec",
   "metadata": {},
   "source": [
    "# Project #3b: Text Generation with GPT-2 Tokenizer and Custom LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c575c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 10.776877584911528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 9.596878732953753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 4.854178587595622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 1.5558494726816814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.5830658362025306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.41575357459840323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.3707735708781651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.34807117212386357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.33293155687195913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.3225305924812953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.31359219551086426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.30663791724613737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.30221578053065706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.296847593216669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.2912673311574118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.28871854004405795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.28425595519088565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.27976368828898385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.27904570528439115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.27526673958415077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.27335261305173236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.2709875071332568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.2698656427008765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.26829912194183897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.26656842870371683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.26522034796930494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.26255490808259874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.26016675042254583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.259043697090376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.2580048264492126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.25577459094070254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.25659418744700296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.25528762666952043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.25595685768695103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.2539448173982756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.25170315908534185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.25077366687002633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.25149698475641863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.24991695228077115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.2506096082783881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.2482366966349738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.24720864636557444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.24723123794510252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.2466051017954236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.24564240553549357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.24516732600473223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.24474052694581805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.2453618578258015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.2464179134085065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.24540535325095766\n",
      "Prompt: But thou shrieking\n",
      "Generated Text: But thou shriPennMilitary cable inhathon essayector Cob Sinn did\n",
      "\n",
      "Prompt: In the quiet\n",
      "Generated Text: In the hers mimic robotic RG turned Threat\n",
      "\n",
      "Prompt: On the sole\n",
      "Generated Text: On the pressures snowy much indexes Ident Michel\n",
      "\n",
      "Prompt: Every fowl of\n",
      "Generated Text: Every fowlWay Holo Solutionnone restart guy dietrowerctl Wake writes effort\n",
      "\n",
      "Prompt: In a mutual flame\n",
      "Generated Text: In a mutualsubmit lakeXP Ramsay hemorCD Boise skepticism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "# Load and prepare the dataset\n",
    "def load_data(file_path, tokenizer, block_size=256):\n",
    "    dataset = load_dataset('text', data_files={'train': file_path})\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, max_length=block_size, padding='max_length')\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "    return tokenized_datasets['train']\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.input_ids = tokenized_texts['input_ids']\n",
    "        self.attention_mask = tokenized_texts['attention_mask']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.attention_mask[idx])\n",
    "\n",
    "data_file = 'poems.txt'\n",
    "tokenized_datasets = load_data(data_file, tokenizer)\n",
    "dataset = TextDataset(tokenized_datasets)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits, hidden\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = len(tokenizer)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "num_layers = 5\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-5\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    hidden = (torch.zeros(num_layers, 4, hidden_dim).to(device),\n",
    "              torch.zeros(num_layers, 4, hidden_dim).to(device))  # Initialize hidden state and cell state\n",
    "    for inputs, _ in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        hidden = (hidden[0].detach(), hidden[1].detach())  # Detach hidden state and cell state for truncated BPTT\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader)}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), './lstm_model.pth')\n",
    "\n",
    "# Generate text with the trained LSTM model\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    input_ids = input_ids[:, :-1]  # Remove the EOS token to prevent it from being considered a part of the prompt\n",
    "    hidden = (torch.zeros(num_layers, 1, hidden_dim).to(device),\n",
    "              torch.zeros(num_layers, 1, hidden_dim).to(device))  # Initialize hidden state and cell state\n",
    "    \n",
    "    generated = input_ids\n",
    "    for _ in range(max_length):\n",
    "        outputs, hidden = model(generated[:, -1].unsqueeze(0), hidden)\n",
    "        next_token_logits = outputs[0, -1, :] / temperature\n",
    "        next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n",
    "        generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "# Example prompts for text generation\n",
    "prompts = [\n",
    "    \"But thou shrieking\",\n",
    "    \"In the quiet\",\n",
    "    \"On the sole\",\n",
    "    \"Every fowl of\",\n",
    "    \"In a mutual flame\"\n",
    "]\n",
    "\n",
    "# Generate and display text based on the example prompts\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    generated_text = generate_text(model, tokenizer, prompt, max_length=50)\n",
    "    print(f\"Generated Text: {generated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697c007",
   "metadata": {},
   "source": [
    "# Project #3c: Text Generation with Custom Tokenizer and Custom LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0e6019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.397375447409494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 5.369072005862281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 5.086614540645054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 4.7722929772876554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 4.701060726529076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 4.661007994697208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 4.6164835180555075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 4.612714812869117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 4.615986642383394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 4.62939437230428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 4.631395805449713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 4.582741941724505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 4.606331053234282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 4.610113756997245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 4.586744263058617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 4.567246459779286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 4.612494604928153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 4.580174729937599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 4.5928690774100165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 4.605668226877849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 4.582527887253534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 4.602342060634068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 4.580337615240188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 4.587628137497675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 4.578118687584286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 4.597377368382046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 4.532333192371187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 4.5667775472005205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 4.574165026346843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 4.582522437686012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 4.552820625759306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 4.575600033714657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 4.436976024082729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 4.592997732616606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 4.57560175941104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 4.562854789552235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 4.567587602706182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 4.559652646382649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 4.577643621535528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 4.587292693910145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 4.503223180770874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 4.561002413431804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 4.585660707382929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 4.570904186793736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 4.573252973102388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 4.5664574191683815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 4.584573041825068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 4.465279125031971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 32.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 4.60325152533395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 33.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 4.560289019630069\n",
      "Prompt: But thou shrieking\n",
      "Generated Text: but thou shrieking lack repair mine divining simple arabian right how\n",
      "\n",
      "Prompt: In the quiet\n",
      "Generated Text: in the is she this of\n",
      "\n",
      "Prompt: On the sole\n",
      "Generated Text: on the sole distincts loudest are co rarity itself reason lov mutual twixt\n",
      "\n",
      "Prompt: Every fowl of\n",
      "Generated Text: every fowl of rest reason called eagle queen\n",
      "\n",
      "Prompt: In a mutual flame\n",
      "Generated Text: in a mutual flame whose precurrer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom tokenizer from scratch\n",
    "class CustomTokenizer:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            tokens = self.tokenize(text)\n",
    "            counter.update(tokens)\n",
    "        \n",
    "        self.vocab_size = len(counter) + 2  # Adding 2 for PAD and EOS tokens\n",
    "        self.word2idx = {word: idx + 2 for idx, (word, _) in enumerate(counter.most_common())}\n",
    "        self.word2idx['<PAD>'] = 0\n",
    "        self.word2idx['<EOS>'] = 1\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        text = re.sub(r'[\\W_]+', ' ', text).lower().strip()\n",
    "        return text.split()\n",
    "\n",
    "    def encode(self, text, max_length=256):\n",
    "        tokens = self.tokenize(text)\n",
    "        token_ids = [self.word2idx.get(token, self.word2idx['<PAD>']) for token in tokens]\n",
    "        token_ids = token_ids[:max_length-1] + [self.word2idx['<EOS>']]\n",
    "        padding = [self.word2idx['<PAD>']] * (max_length - len(token_ids))\n",
    "        return token_ids + padding\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        tokens = [self.idx2word[token_id] for token_id in token_ids if token_id not in {self.word2idx['<PAD>'], self.word2idx['<EOS>']}]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "# Load and prepare the dataset\n",
    "def load_data(file_path, tokenizer, block_size=256):\n",
    "    with open(file_path, 'r') as f:\n",
    "        texts = f.readlines()\n",
    "    \n",
    "    tokenizer.build_vocab(texts)\n",
    "    tokenized_texts = [tokenizer.encode(text, max_length=block_size) for text in texts]\n",
    "    return tokenized_texts\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.input_ids = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.input_ids[idx])\n",
    "\n",
    "data_file = 'poems.txt'\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenized_texts = load_data(data_file, tokenizer)\n",
    "dataset = TextDataset(tokenized_texts)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits, hidden\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "num_layers = 5\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-5\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.word2idx['<PAD>'])\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    hidden = (torch.zeros(num_layers, 4, hidden_dim).to(device),\n",
    "              torch.zeros(num_layers, 4, hidden_dim).to(device))  # Initialize hidden state and cell state\n",
    "    for inputs, _ in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "        hidden = (hidden[0].detach(), hidden[1].detach())  # Detach hidden state and cell state for truncated BPTT\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), inputs.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader)}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), './lstm_model.pth')\n",
    "\n",
    "# Generate text with the trained LSTM model\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(tokenizer.encode(prompt)[:-1]).unsqueeze(0).to(device)  # Remove the EOS token to prevent it from being considered a part of the prompt\n",
    "    hidden = (torch.zeros(num_layers, 1, hidden_dim).to(device),\n",
    "              torch.zeros(num_layers, 1, hidden_dim).to(device))  # Initialize hidden state and cell state\n",
    "    \n",
    "    generated = input_ids\n",
    "    for _ in range(max_length):\n",
    "        outputs, hidden = model(generated[:, -1].unsqueeze(0), hidden)\n",
    "        next_token_logits = outputs[0, -1, :] / temperature\n",
    "        next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n",
    "        generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
    "        if next_token.item() == tokenizer.word2idx['<EOS>']:\n",
    "            break\n",
    "    \n",
    "    return tokenizer.decode(generated[0].tolist())\n",
    "\n",
    "# Example prompts for text generation\n",
    "prompts = [\n",
    "    \"But thou shrieking\",\n",
    "    \"In the quiet\",\n",
    "    \"On the sole\",\n",
    "    \"Every fowl of\",\n",
    "    \"In a mutual flame\"\n",
    "]\n",
    "\n",
    "# Generate and display text based on the example prompts\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    generated_text = generate_text(model, tokenizer, prompt, max_length=50)\n",
    "    print(f\"Generated Text: {generated_text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
