{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0001db5c-05df-45d6-b61d-926d9bbe77bd",
   "metadata": {},
   "source": [
    "# import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b4da6b-04be-485a-8b10-feef0b4b1d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as vec\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    " \n",
    "print(\"rocks :\", wnl.lemmatize(\"rocks\",pos ='n'))\n",
    "print(\"corpora :\", wnl.lemmatize(\"corpora\", pos = 'n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec6a99-4e37-40c0-b4c9-70c30133ad25",
   "metadata": {},
   "source": [
    "# Take datasets from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c9a20c4-2ca5-4c49-b962-02d37af16722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661bf991-cdd7-4c45-b21e-b5ba8e0728c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane ! is considered among many to be the ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you've got to love disney . \\nno matter what t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" the tailor of panama \" is a different kind ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the characters in jonathan lynn's \" the whole ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vikings v . bears ? \\nno , this isn't the line...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>trekkies , roger nygard's energetic and hilari...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>\" dangerous beauty \" is a really nothing more...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>starring shawnee smith ; donovan leitch ; rick...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>man , this was one wierd movie . \\nsimilar to ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>review : ghost dog : the way of the samurai ( ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews_content  category\n",
       "0     airplane ! is considered among many to be the ...  positive\n",
       "1     you've got to love disney . \\nno matter what t...  positive\n",
       "2      \" the tailor of panama \" is a different kind ...  positive\n",
       "3     the characters in jonathan lynn's \" the whole ...  negative\n",
       "4     vikings v . bears ? \\nno , this isn't the line...  negative\n",
       "...                                                 ...       ...\n",
       "1495  trekkies , roger nygard's energetic and hilari...  positive\n",
       "1496   \" dangerous beauty \" is a really nothing more...  positive\n",
       "1497  starring shawnee smith ; donovan leitch ; rick...  negative\n",
       "1498  man , this was one wierd movie . \\nsimilar to ...  negative\n",
       "1499  review : ghost dog : the way of the samurai ( ...  positive\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665375c7-07c9-4891-bf02-4528f36d1b6b",
   "metadata": {},
   "source": [
    "# define function for reprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412b67bd-457e-4499-8018-c4187df03b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alphabetic(text):\n",
    "    # Use regular expression to remove non-alphabetic characters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "def wordnet_lemmatizer(text):\n",
    "    words = text.split()\n",
    "    output = [wnl.lemmatize(element) for element in words]\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "133c5f03-c016-4448-9748-aac3ac142dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['processed text'] = df_train['reviews_content'].apply(extract_alphabetic)\n",
    "df_train['processed text'] = df_train['processed text'].apply(wordnet_lemmatizer)\n",
    "\n",
    "df_test['processed text'] = df_test['reviews_content'].apply(extract_alphabetic)\n",
    "df_test['processed text'] = df_test['processed text'].apply(wordnet_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35086b18-48b4-41a6-9f47-80aaf4ed88de",
   "metadata": {},
   "source": [
    "# Perform TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b379df2a-2379-4f60-9d1e-427d5c2a664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vec(ngram_range = (1,3),min_df = 8,max_df = 1000, norm= 'l2')\n",
    "vect.fit(df_train['processed text'])\n",
    "X_train = vect.transform(df_train['processed text'])\n",
    "X_train = X_train.toarray()\n",
    "df_train['category'] = df_train['category'].replace({'positive':1,'negative':0})\n",
    "y_train = df_train['category']\n",
    "\n",
    "X_test = vect.transform(df_test['processed text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c045d674-fc16-4273-aa24-f186e724a3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_content</th>\n",
       "      <th>category</th>\n",
       "      <th>processed text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane ! is considered among many to be the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>airplane is considered among many to be the ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you've got to love disney . \\nno matter what t...</td>\n",
       "      <td>1</td>\n",
       "      <td>youve got to love disney no matter what they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" the tailor of panama \" is a different kind ...</td>\n",
       "      <td>1</td>\n",
       "      <td>the tailor of panama is a different kind of sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the characters in jonathan lynn's \" the whole ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the character in jonathan lynns the whole nine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vikings v . bears ? \\nno , this isn't the line...</td>\n",
       "      <td>0</td>\n",
       "      <td>viking v bear no this isnt the lineup for mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>trekkies , roger nygard's energetic and hilari...</td>\n",
       "      <td>1</td>\n",
       "      <td>trekkies roger nygards energetic and hilarious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>\" dangerous beauty \" is a really nothing more...</td>\n",
       "      <td>1</td>\n",
       "      <td>dangerous beauty is a really nothing more than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>starring shawnee smith ; donovan leitch ; rick...</td>\n",
       "      <td>0</td>\n",
       "      <td>starring shawnee smith donovan leitch ricky pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>man , this was one wierd movie . \\nsimilar to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>man this wa one wierd movie similar to conspir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>review : ghost dog : the way of the samurai ( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>review ghost dog the way of the samurai cast f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews_content  category  \\\n",
       "0     airplane ! is considered among many to be the ...         1   \n",
       "1     you've got to love disney . \\nno matter what t...         1   \n",
       "2      \" the tailor of panama \" is a different kind ...         1   \n",
       "3     the characters in jonathan lynn's \" the whole ...         0   \n",
       "4     vikings v . bears ? \\nno , this isn't the line...         0   \n",
       "...                                                 ...       ...   \n",
       "1495  trekkies , roger nygard's energetic and hilari...         1   \n",
       "1496   \" dangerous beauty \" is a really nothing more...         1   \n",
       "1497  starring shawnee smith ; donovan leitch ; rick...         0   \n",
       "1498  man , this was one wierd movie . \\nsimilar to ...         0   \n",
       "1499  review : ghost dog : the way of the samurai ( ...         1   \n",
       "\n",
       "                                         processed text  \n",
       "0     airplane is considered among many to be the ep...  \n",
       "1     youve got to love disney no matter what they s...  \n",
       "2     the tailor of panama is a different kind of sp...  \n",
       "3     the character in jonathan lynns the whole nine...  \n",
       "4     viking v bear no this isnt the lineup for mond...  \n",
       "...                                                 ...  \n",
       "1495  trekkies roger nygards energetic and hilarious...  \n",
       "1496  dangerous beauty is a really nothing more than...  \n",
       "1497  starring shawnee smith donovan leitch ricky pa...  \n",
       "1498  man this wa one wierd movie similar to conspir...  \n",
       "1499  review ghost dog the way of the samurai cast f...  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e564ca-a96f-48a4-9f77-5cc72f7ecc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 28/29 [09:49<00:29, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 369, number of negative: 381\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87223\n",
      "[LightGBM] [Info] Number of data points in the train set: 750, number of used features: 3904\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492000 -> initscore=-0.032003\n",
      "[LightGBM] [Info] Start training from score -0.032003\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [10:03<00:00, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LogisticRegression                 0.85               0.85     0.85      0.85   \n",
      "PassiveAggressiveClassifier        0.85               0.85     0.85      0.85   \n",
      "ExtraTreesClassifier               0.84               0.84     0.84      0.84   \n",
      "LinearSVC                          0.84               0.84     0.84      0.84   \n",
      "RidgeClassifierCV                  0.84               0.84     0.84      0.84   \n",
      "RidgeClassifier                    0.84               0.84     0.84      0.84   \n",
      "CalibratedClassifierCV             0.84               0.84     0.84      0.84   \n",
      "Perceptron                         0.83               0.83     0.83      0.83   \n",
      "NearestCentroid                    0.83               0.83     0.83      0.83   \n",
      "NuSVC                              0.81               0.82     0.82      0.81   \n",
      "SGDClassifier                      0.81               0.81     0.81      0.81   \n",
      "BernoulliNB                        0.79               0.79     0.79      0.78   \n",
      "SVC                                0.78               0.79     0.79      0.78   \n",
      "LGBMClassifier                     0.78               0.78     0.78      0.78   \n",
      "XGBClassifier                      0.77               0.77     0.77      0.77   \n",
      "RandomForestClassifier             0.76               0.76     0.76      0.76   \n",
      "LinearDiscriminantAnalysis         0.75               0.76     0.76      0.75   \n",
      "AdaBoostClassifier                 0.72               0.72     0.72      0.72   \n",
      "BaggingClassifier                  0.69               0.69     0.69      0.69   \n",
      "DecisionTreeClassifier             0.62               0.62     0.62      0.62   \n",
      "GaussianNB                         0.62               0.61     0.61      0.61   \n",
      "ExtraTreeClassifier                0.59               0.59     0.59      0.59   \n",
      "KNeighborsClassifier               0.52               0.53     0.53      0.39   \n",
      "QuadraticDiscriminantAnalysis      0.53               0.52     0.52      0.44   \n",
      "LabelSpreading                     0.49               0.50     0.50      0.32   \n",
      "LabelPropagation                   0.49               0.50     0.50      0.32   \n",
      "DummyClassifier                    0.49               0.50     0.50      0.32   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LogisticRegression                   5.00  \n",
      "PassiveAggressiveClassifier          6.88  \n",
      "ExtraTreesClassifier                19.18  \n",
      "LinearSVC                           13.67  \n",
      "RidgeClassifierCV                    7.40  \n",
      "RidgeClassifier                      7.07  \n",
      "CalibratedClassifierCV              29.19  \n",
      "Perceptron                           6.69  \n",
      "NearestCentroid                      5.15  \n",
      "NuSVC                               84.99  \n",
      "SGDClassifier                        5.31  \n",
      "BernoulliNB                          7.08  \n",
      "SVC                                 75.25  \n",
      "LGBMClassifier                      14.91  \n",
      "XGBClassifier                       56.44  \n",
      "RandomForestClassifier              10.72  \n",
      "LinearDiscriminantAnalysis          34.32  \n",
      "AdaBoostClassifier                  62.36  \n",
      "BaggingClassifier                   59.60  \n",
      "DecisionTreeClassifier              13.37  \n",
      "GaussianNB                           6.54  \n",
      "ExtraTreeClassifier                  5.33  \n",
      "KNeighborsClassifier                 9.26  \n",
      "QuadraticDiscriminantAnalysis       31.22  \n",
      "LabelSpreading                       9.75  \n",
      "LabelPropagation                     9.78  \n",
      "DummyClassifier                      4.52  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,test_size=.5,random_state =123)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883a8ae-20b8-40c7-a0db-8c5e042fa2b7",
   "metadata": {},
   "source": [
    "# fine-tuning regularization constant C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "943f461f-2e27-4e63-92b8-f0534ea708c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.10 avg - 0.84 median - 0.84\n",
      "C = 0.20 avg - 0.85 median - 0.86\n",
      "C = 0.30 avg - 0.86 median - 0.85\n",
      "C = 0.40 avg - 0.86 median - 0.85\n",
      "C = 0.50 avg - 0.86 median - 0.86\n",
      "C = 0.60 avg - 0.86 median - 0.86\n",
      "C = 0.70 avg - 0.86 median - 0.86\n",
      "C = 0.80 avg - 0.86 median - 0.86\n",
      "C = 0.90 avg - 0.87 median - 0.86\n",
      "C = 1.00 avg - 0.87 median - 0.86\n",
      "C = 1.10 avg - 0.87 median - 0.86\n",
      "C = 1.20 avg - 0.87 median - 0.86\n",
      "C = 1.30 avg - 0.87 median - 0.86\n",
      "C = 1.40 avg - 0.87 median - 0.86\n",
      "C = 1.50 avg - 0.87 median - 0.86\n",
      "C = 1.60 avg - 0.87 median - 0.86\n",
      "C = 1.70 avg - 0.87 median - 0.86\n",
      "C = 1.80 avg - 0.87 median - 0.86\n",
      "C = 1.90 avg - 0.87 median - 0.86\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,2,0.1):\n",
    "    model = LinearSVC(tol = 0.001, C = i,dual ='auto')\n",
    "    result = cross_val_score(model, X_train,y_train,cv = 15)\n",
    "    print(f'C = {i:.2f} avg - {np.mean(result):.2f} median - {np.median(result):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef9d48-14e5-44e5-9342-4f2d853caa88",
   "metadata": {},
   "source": [
    "now we choose $C = 0.9$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d661ff2-9a14-4218-918f-dd40a762fc14",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25484736-b57c-4a11-a2bc-eba284755394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(tol = 0.001, C = 0.9, dual = 'auto')\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba1cac-55d3-40ef-bc92-7b61eaacdc4c",
   "metadata": {},
   "source": [
    "# Make the CSV files to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64105aff-0fdc-4eeb-a130-bf97d53e19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.DataFrame({'Row': range(1,501), 'Label':y_predict})\n",
    "output_file.to_csv('SVM_.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
