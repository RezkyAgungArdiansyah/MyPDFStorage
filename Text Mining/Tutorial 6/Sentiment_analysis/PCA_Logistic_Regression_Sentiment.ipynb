{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q review_polarity.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474bdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./review_polarity/txt_sentoken/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c502bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'review_polarity\\\\txt_sentoken\\\\pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     all_reviews_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_reviews)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_reviews_df\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43m_read_all_reviews_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36m_read_all_reviews_\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_all_reviews_\u001b[39m():\n\u001b[0;32m      4\u001b[0m     all_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pl\u001b[38;5;241m.\u001b[39mPath(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miterdir():\n\u001b[0;32m      6\u001b[0m         file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(p, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m         all_reviews\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews_content\u001b[39m\u001b[38;5;124m'\u001b[39m: file\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pathlib.py:931\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    928\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 931\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_child_relpath(name)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'review_polarity\\\\txt_sentoken\\\\pos'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "def _read_all_reviews_():\n",
    "    all_reviews = []\n",
    "    for p in pl.Path(data_path+'pos').iterdir():\n",
    "        file = open(p, 'r')\n",
    "        all_reviews.append({'reviews_content': file.read(), 'category': 'positive'})\n",
    "        file.close()\n",
    "    for p in pl.Path(data_path+'neg').iterdir():\n",
    "        file = open(p, 'r')\n",
    "        all_reviews.append({'reviews_content': file.read(), 'category': 'negative'})\n",
    "        file.close()\n",
    "    all_reviews_df = pd.DataFrame(all_reviews)\n",
    "    return all_reviews_df\n",
    "print(_read_all_reviews_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim #when need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad323e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=100, learning_rate=0.02, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count()\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(preprocess_string(row['reviews_content']), [index]) for index, row in df_x.iterrows()]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(preprocess_string(row['reviews_content']))\n",
    "                                     for index, row in df_x.iterrows()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_build_model():\n",
    "    all_reviews_df = _read_all_reviews_()\n",
    "    train_x_df, test_x_df, train_y_df, test_y_df = train_test_split(all_reviews_df[['reviews_content']], \n",
    "                                                                    all_reviews_df[['category']])\n",
    "\n",
    "#     print((train_x_df))\n",
    "#     print(len(test_x_df))\n",
    "#     asdsa\n",
    "    train_x_df.to_csv(\"train_x_df.csv\")\n",
    "    train_y_df.to_csv(\"train_y_df.csv\")\n",
    "    test_x_df.to_csv(\"test_x_df.csv\")\n",
    "    test_y_df.to_csv(\"test_y_df.csv\")\n",
    "        \n",
    "    pl = Pipeline(steps=[('doc2vec', Doc2VecTransformer(vector_size=220)),\n",
    "                         ('pca', PCA(n_components=100)),\n",
    "                         ('logistic', LogisticRegression())\n",
    "                         ])\n",
    "    pl.fit(train_x_df[['reviews_content']], train_y_df[['category']])\n",
    "    predictions_y = pl.predict(test_x_df[['reviews_content']])\n",
    "    print(predictions_y)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_true=test_y_df[['category']], y_pred=predictions_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_long_range_grid_search():\n",
    "    all_reviews_df = _read_all_reviews_()\n",
    "    train_x_df, test_x_df, train_y_df, test_y_df = train_test_split(all_reviews_df[['reviews_content']], \n",
    "                                                                    all_reviews_df[['category']])\n",
    "    \n",
    "    pl = Pipeline(steps=[('doc2vec', Doc2VecTransformer()),\n",
    "                         ('pca', PCA()),\n",
    "                         ('logistic', LogisticRegression())\n",
    "                         ])\n",
    "\n",
    "    param_grid = {\n",
    "        'doc2vec__vector_size': [x for x in range(100, 250)],\n",
    "        'pca__n_components': [x for x in range(1, 50)]\n",
    "    }\n",
    "    gs_cv = GridSearchCV(estimator=pl, param_grid=param_grid, cv=5, n_jobs=-1,\n",
    "                         scoring=\"accuracy\")\n",
    "    gs_cv.fit(train_x_df[['reviews_content']], train_y_df[['category']])\n",
    "\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % gs_cv.best_score_)\n",
    "    print(gs_cv.best_params_)\n",
    "    predictions_y = gs_cv.predict(test_x_df[['reviews_content']])\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_true=test_y_df[['category']], y_pred=predictions_y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_short_range_grid_search():\n",
    "    all_reviews_df = _read_all_reviews_()\n",
    "    train_x_df, test_x_df, train_y_df, test_y_df = train_test_split(all_reviews_df[['reviews_content']], \n",
    "                                                                    all_reviews_df[['category']])\n",
    "\n",
    "    pl = Pipeline(steps=[('doc2vec', Doc2VecTransformer()),\n",
    "                         ('pca', PCA()),\n",
    "                         ('logistic', LogisticRegression())\n",
    "                         ])\n",
    "\n",
    "    param_grid = {\n",
    "        'doc2vec__vector_size': [200, 220, 250],\n",
    "        'pca__n_components': [50, 75, 100]\n",
    "    }\n",
    "    gs_cv = GridSearchCV(estimator=pl, param_grid=param_grid, cv=3, n_jobs=-1,\n",
    "                         scoring=\"accuracy\")\n",
    "    gs_cv.fit(train_x_df[['reviews_content']], train_y_df[['category']])\n",
    "\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % gs_cv.best_score_)\n",
    "    print(gs_cv.best_params_)\n",
    "    predictions_y = gs_cv.predict(test_x_df[['reviews_content']])\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_true=test_y_df[['category']], y_pred=predictions_y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
