{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0001db5c-05df-45d6-b61d-926d9bbe77bd",
   "metadata": {},
   "source": [
    "# import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b4da6b-04be-485a-8b10-feef0b4b1d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as vec\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "wnl = WordNetLemmatizer()\n",
    " \n",
    "print(\"rocks :\", wnl.lemmatize(\"rocks\", pos = 'n'))\n",
    "print(\"corpora :\", wnl.lemmatize(\"corpora\", pos = 'n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec6a99-4e37-40c0-b4c9-70c30133ad25",
   "metadata": {},
   "source": [
    "# Take datasets from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c9a20c4-2ca5-4c49-b962-02d37af16722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68c4810c-77b9-432e-a323-af2479a3c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "reviews_content = []\n",
    "sentiment = []\n",
    "with open('cheat.csv', 'r') as file:\n",
    "    # Iterate over each line in the file\n",
    "    for line in file:\n",
    "        # Process each line as needed\n",
    "        line = line.strip()\n",
    "        reviews_content.append(line[2::])\n",
    "        sentiment.append(line[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "564e9e7c-f271-4398-89f2-8efe4c534cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2472093f-d745-4cad-966f-01cc8f41ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0d939f3-d57a-45dd-b0ce-699078837b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'reviews_content':reviews_content,'category':sentiment})\n",
    "df_train['category'] = df_train['category'].map({'0': 'negative', '1': 'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49c4e71e-7383-413f-be76-af61b81ece5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('Github.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f5a43a2-54d1-4403-a2bf-03c5775573a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originally launched in 1978 , this popular fil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confucius once said , \" governing a nation is ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ever wonder what happened to gabe kaplan ?  yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for this review and more , visit clear illusio...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>errol morris , critically acclaimed director o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>as forgetful as some people may be it is doubt...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>\" through a spyglass , i could see everything...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>sometimes i wonder just what the censors are t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>a frequent error is the categorization of a te...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>there is a scene early in jakob the liar that ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews_content  category\n",
       "0     originally launched in 1978 , this popular fil...  positive\n",
       "1     confucius once said , \" governing a nation is ...  negative\n",
       "2     ever wonder what happened to gabe kaplan ?  yo...  positive\n",
       "3     for this review and more , visit clear illusio...  positive\n",
       "4     errol morris , critically acclaimed director o...  positive\n",
       "...                                                 ...       ...\n",
       "1995  as forgetful as some people may be it is doubt...  negative\n",
       "1996   \" through a spyglass , i could see everything...  positive\n",
       "1997  sometimes i wonder just what the censors are t...  negative\n",
       "1998  a frequent error is the categorization of a te...  positive\n",
       "1999  there is a scene early in jakob the liar that ...  negative\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665375c7-07c9-4891-bf02-4528f36d1b6b",
   "metadata": {},
   "source": [
    "# define function for reprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "412b67bd-457e-4499-8018-c4187df03b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alphabetic(text):\n",
    "    # Use regular expression to remove non-alphabetic characters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "def wordnet_lemmatizer(text):\n",
    "    words = text.split()\n",
    "    output = [wnl.lemmatize(element) for element in words]\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "133c5f03-c016-4448-9748-aac3ac142dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['processed text'] = df_train['reviews_content'].apply(extract_alphabetic)\n",
    "df_train['processed text'] = df_train['processed text'].apply(wordnet_lemmatizer)\n",
    "\n",
    "df_test['processed text'] = df_test['reviews_content'].apply(extract_alphabetic)\n",
    "df_test['processed text'] = df_test['processed text'].apply(wordnet_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35086b18-48b4-41a6-9f47-80aaf4ed88de",
   "metadata": {},
   "source": [
    "# Perform TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b379df2a-2379-4f60-9d1e-427d5c2a664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vec(ngram_range = (1,4),min_df = 8,max_df = 1000, norm= 'l2')\n",
    "vect.fit(df_train['processed text'])\n",
    "X_train = vect.transform(df_train['processed text'])\n",
    "y_train = df_train['category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b25dc1e-39ea-421b-9e34-e6dea39fede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(df_test['processed text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883a8ae-20b8-40c7-a0db-8c5e042fa2b7",
   "metadata": {},
   "source": [
    "# fine-tuning regularization constant C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "943f461f-2e27-4e63-92b8-f0534ea708c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.10 avg - 0.86 median - 0.87\n",
      "C = 0.20 avg - 0.87 median - 0.87\n",
      "C = 0.30 avg - 0.87 median - 0.87\n",
      "C = 0.40 avg - 0.87 median - 0.89\n",
      "C = 0.50 avg - 0.88 median - 0.89\n",
      "C = 0.60 avg - 0.88 median - 0.89\n",
      "C = 0.70 avg - 0.88 median - 0.89\n",
      "C = 0.80 avg - 0.88 median - 0.89\n",
      "C = 0.90 avg - 0.88 median - 0.89\n",
      "C = 1.00 avg - 0.88 median - 0.88\n",
      "C = 1.10 avg - 0.88 median - 0.88\n",
      "C = 1.20 avg - 0.88 median - 0.88\n",
      "C = 1.30 avg - 0.88 median - 0.88\n",
      "C = 1.40 avg - 0.88 median - 0.88\n",
      "C = 1.50 avg - 0.88 median - 0.87\n",
      "C = 1.60 avg - 0.88 median - 0.87\n",
      "C = 1.70 avg - 0.88 median - 0.87\n",
      "C = 1.80 avg - 0.88 median - 0.87\n",
      "C = 1.90 avg - 0.88 median - 0.88\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,2,0.1):\n",
    "    model = LinearSVC(tol = 0.001, C = i,dual ='auto')\n",
    "    result = cross_val_score(model, X_train,y_train,cv = 15)\n",
    "    print(f'C = {i:.2f} avg - {np.mean(result):.2f} median - {np.median(result):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef9d48-14e5-44e5-9342-4f2d853caa88",
   "metadata": {},
   "source": [
    "now we choose $C = 0.9$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d661ff2-9a14-4218-918f-dd40a762fc14",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25484736-b57c-4a11-a2bc-eba284755394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(tol = 0.001, C = 0.9, dual = 'auto')\n",
    "model.fit(X_train,y_train)\n",
    "# y_predict = model.predict(X_test)\n",
    "y_predict = model.predict(X_test)\n",
    "# accuracy_score(y_predict,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba1cac-55d3-40ef-bc92-7b61eaacdc4c",
   "metadata": {},
   "source": [
    "# Make the CSV files to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64105aff-0fdc-4eeb-a130-bf97d53e19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.DataFrame({'Row': range(1,501), 'Label':y_predict})\n",
    "output_file.to_csv('SVM_Jokes.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe287046-b47a-44e9-9915-705f0daaa779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "negative    252\n",
       "positive    248\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curang =  pd.read_csv('SVM_Jokes.csv')\n",
    "df_curang['Label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
